{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт необходимых модулей и определение констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import decomposition\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 21\n",
    "np.random.seed(SEED)\n",
    "IMAGE_PATH = \"./data/Raw/\"\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка набора данных и предварительный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции отрисовки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка нескольких изображений по пути файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pictures(img_df):\n",
    "    n = len(img_df)\n",
    "    cols = 5\n",
    "    if n < cols:\n",
    "        cols = n\n",
    "    rows = n//cols+1 if (n/cols > n//cols) else n//cols\n",
    "    plt.subplots(squeeze=False, figsize=(10, 10), constrained_layout=True)\n",
    "    plt.grid(False)\n",
    "    for i in range(n):\n",
    "        plt.subplot2grid((rows, cols), (i//cols, i % cols)\n",
    "                         ).imshow(imread(img_df['path'][i]))\n",
    "        plt.title(img_df['img_label'][i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка одного изображения с его цветовой гистограммой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image_with_hist(image):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n",
    "    axes[0].imshow(array_to_img(image))\n",
    "    axes[1].hist(image.ravel(), bins=256, color='orange')\n",
    "    axes[1].hist(image[:, :, 0].ravel(), bins=256, color='red', alpha=0.5)\n",
    "    axes[1].hist(image[:, :, 1].ravel(), bins=256, color='Green', alpha=0.5)\n",
    "    axes[1].hist(image[:, :, 2].ravel(), bins=256, color='Blue', alpha=0.5)\n",
    "    axes[1].set_xlabel('Интенсивность')\n",
    "    axes[1].set_ylabel('Количество')\n",
    "    axes[1].legend(['Общая', 'Красный канал', 'Зелёный канал', 'Синий канал'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка нескольких изображений с их цветовыми гистограммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pictures_with_hists(img_df):\n",
    "    n = len(img_df)\n",
    "    cols = 5\n",
    "    if n < cols:\n",
    "        cols = n\n",
    "    rows = n//cols+1 if (n/cols > n//cols) else n//cols\n",
    "    fig, axes = plt.subplots(\n",
    "        rows*2, cols, figsize=(cols*5, rows*10), constrained_layout=True)\n",
    "    fig.suptitle('Цветовая гистограмма', fontsize=21)\n",
    "    row_i = 0\n",
    "    for i in range(n):\n",
    "        image = imread(img_df['path'][i])\n",
    "        axes[row_i, i % cols].hist(image.ravel(), bins=256, color='orange', )\n",
    "        axes[row_i, i % cols].hist(\n",
    "            image[:, :, 0].ravel(), bins=256, color='red', alpha=0.5)\n",
    "        axes[row_i, i % cols].hist(\n",
    "            image[:, :, 1].ravel(), bins=256, color='green', alpha=0.5)\n",
    "        axes[row_i, i % cols].hist(\n",
    "            image[:, :, 2].ravel(), bins=256, color='blue', alpha=0.5)\n",
    "        axes[row_i, i % cols].legend(\n",
    "            ['Общая', 'Красный канал', 'Зелёный канал', 'Синий канал'])\n",
    "        axes[row_i, i % cols].set_xlabel('Интенсивность')\n",
    "        axes[row_i, i % cols].set_ylabel('Количество')\n",
    "        axes[row_i+1, i % cols].imshow(image)\n",
    "        if (i % cols+1 == cols):\n",
    "            row_i += 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных для датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция выделения признаков из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_params(img_path):\n",
    "    img = imread(img_path)\n",
    "    img_class = img_path.replace(IMAGE_PATH, '').split('\\\\')[0]\n",
    "    img_color = np.sum(img.reshape(-1, 3)*np.asarray([65536, 256, 1]), axis=1)\n",
    "    return classes_dict[img_class.lower()], img_class, img_path, img.shape[0], img.shape[1], img.shape[2], img_color.max(), img_color.min(), img_color.mean(), img_color.std(), np.median(img_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = []\n",
    "classes_dict = {}\n",
    "for k, dir in enumerate(os.listdir(IMAGE_PATH)):\n",
    "    classes_dict[dir.lower()] = k\n",
    "    image_files.extend(os.path.join(IMAGE_PATH, dir, file) for file in os.listdir(\n",
    "        os.path.join(IMAGE_PATH, dir)) if file.endswith(('.JPG', '.jpg', '.png')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пронумерованные классы датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_title, class_number in classes_dict.items():\n",
    "    print(f\"Класс: \\033[1m{class_title}\\033[0m - номер {class_number}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание датасета признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = np.array(list(map(img_params, np.asarray(image_files))))\n",
    "df = pd.DataFrame(columns=['img_class', 'img_label', 'path', 'height', 'width', 'dimension',\n",
    "                  'max_rgb', 'min_rgb', 'mean_rgb', 'std_rgb', 'median_rgb'], data=images_data)\n",
    "df = df.astype({'height': 'int32', 'width': 'int32', 'dimension': 'int32', 'max_rgb': 'float32',\n",
    "                'min_rgb': 'float32', 'mean_rgb': 'float32', 'std_rgb': 'float32', 'median_rgb': 'float32'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состав полей датасета:\n",
    "- **img_class** - класс, к которому относится изображение\n",
    "- **img_label** - название класса, к которому относится изображение\n",
    "- **path** - путь к файлу изображения\n",
    "- **height** - высота изображения\n",
    "- **width** - ширина изображения\n",
    "- **dimension** - количество цветовых каналов изображения\n",
    "- **max_rgb** - максимальное значение пикселя в изображении\n",
    "- **min_rgb** - минимальное значение пикселя в изображении\n",
    "- **mean_rgb** - среднее значение пикселя в изображении\n",
    "- **std_rgb**  - стандартное отклонение значения пикселя в изображении\n",
    "- **median_rgb** - медианное значение пикселя в изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Количество фотографий в датасете: {df.shape[0]}')\n",
    "print('Количество отсутствующих значений в датасете и типы данных по столбцам:\\n')\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Несколько точек данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Первые 5 строчек датасета:')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Первые 5 изображений датасета:')\n",
    "draw_pictures(df[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Изображения экземпляров разных классов:')\n",
    "draw_pictures(df.groupby('img_class').min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описательный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание численных типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Визуализация численных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle(\n",
    "    'Визуализация шкалы измерения и аномальных значений высоты и ширины изображений')\n",
    "sns.boxplot(ax=axes[0], y=\"height\", data=df, color='green')\n",
    "sns.boxplot(ax=axes[1], y=\"width\", data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle(\n",
    "    'Визуализация шкалы измерения и аномальных значений высоты и ширины изображений в соответствии с классом')\n",
    "sns.boxplot(ax=axes[0], x=\"img_label\", y=\"height\", data=df)\n",
    "sns.boxplot(ax=axes[1], x=\"img_label\", y=\"width\", data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('Визуализация распределения высоты и ширины изображения ')\n",
    "sns.violinplot(ax=axes[0], y=df['height'], color='purple')\n",
    "sns.violinplot(ax=axes[1], y=df['width'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(25, 7))\n",
    "f.suptitle(\n",
    "    'Графики максимального, минимального, медианного и среднего RGB значения изображения')\n",
    "sns.lineplot(label='Максимальное', data=df['max_rgb'], lw=2)\n",
    "sns.lineplot(label='Медиана', data=df['median_rgb'], lw=2)\n",
    "sns.lineplot(label='Среднее', data=df['mean_rgb'], lw=2)\n",
    "sns.lineplot(label='Минимальное', data=df['min_rgb'], lw=2)\n",
    "plt.fill_between(df.index, df['min_rgb'], df['max_rgb'],\n",
    "                 edgecolor='none', facecolor='blue', alpha=0.1)\n",
    "plt.legend(fontsize=12, loc='upper left')\n",
    "plt.xlabel('Номер изображения')\n",
    "plt.ylabel('RGB значение пикселя')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "fig.suptitle('Визуализация распределения цвета фотографий')\n",
    "sns.histplot(ax=axes[0, 0], data=df, x=\"max_rgb\", hue=\"img_label\",\n",
    "             kde=True, bins=10, line_kws=dict(linewidth=2))\n",
    "sns.histplot(ax=axes[0, 1], data=df, x=\"min_rgb\", hue=\"img_label\",\n",
    "             kde=True, bins=10, line_kws=dict(linewidth=2))\n",
    "sns.histplot(ax=axes[1, 0], data=df, x=\"mean_rgb\", hue=\"img_label\",\n",
    "             kde=True, bins=10, line_kws=dict(linewidth=2))\n",
    "sns.histplot(ax=axes[1, 1], data=df, x=\"median_rgb\",\n",
    "             hue=\"img_label\", kde=True, bins=10, line_kws=dict(linewidth=2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_color(number):\n",
    "    return '#'+hex(int(number)).replace('0x', '').rjust(6, '0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decribe = df.describe()\n",
    "cols = df_decribe.columns[3:].drop('std_rgb')\n",
    "params = ['max', '50%', 'min']\n",
    "n = 2\n",
    "fig, axes = plt.subplots(len(cols), len(\n",
    "    params), figsize=(n*4, n*4), constrained_layout=True)\n",
    "fig.suptitle('Основные цвета фотографий')\n",
    "for i, label in enumerate(cols):\n",
    "    for j, param in enumerate(params):\n",
    "        axes[i, j].fill([0, 0, n, n], [0, n, n, 0],\n",
    "                        number_to_color(df_decribe[label][param]))\n",
    "        axes[i, j].axis('off')\n",
    "        axes[i, j].set_title(f\"{label} {param}\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 5))\n",
    "f.suptitle('График среднего RGB значения изображения со стандартным отклонением')\n",
    "sns.lineplot(label='Среднее', data=df['mean_rgb'], color='blue', lw=2)\n",
    "plt.fill_between(df.index, df['mean_rgb'] - df['std_rgb'], df['mean_rgb'] + df['std_rgb'], edgecolor='none',\n",
    "                 facecolor='blue', alpha=0.2)\n",
    "plt.legend(fontsize=10, loc='upper left')\n",
    "plt.xlabel('Номер изображения')\n",
    "plt.ylabel('RGB значение пикселя')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 7)\n",
    "plt.title(\"Корреляционная матрица признаков датасета\")\n",
    "sns.heatmap(df.drop('dimension', axis=1).corr())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16, 10), constrained_layout=True)\n",
    "for i, col in enumerate(df.columns[3:]):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.scatter(df[col], df['img_label'])\n",
    "    plt.title(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание категориальных типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['O'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение данных внутри датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_title, class_number in classes_dict.items():\n",
    "    print(\n",
    "        f\"Класс номер {class_number} {class_title}: {len(df[df['img_class'] == str(class_number)])} ({len(df[df['img_class'] == str(class_number)])/len(df)*100:.2f}%)\")\n",
    "print(f\"Всего: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "df.groupby('img_label').count()['img_class'].plot(kind='pie', autopct='%1.2f%%',\n",
    "                                                  startangle=270, fontsize=12, title=\"Распределение данных внутри датасета\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цветовые гистограммы по трём каналам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_pictures_with_hists(df[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление экземпляров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция изменения размера датасета до определенного количества экземпляров каждого класса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data_size(train_generator, max_items=100, suf_dir=''):\n",
    "    working_dir = os.path.join(os.path.relpath(os.path.join(\n",
    "        train_generator.directory, \"../\")), f'Work_{suf_dir}')\n",
    "    if os.path.isdir(working_dir):\n",
    "        shutil.rmtree(working_dir)\n",
    "    os.mkdir(working_dir)\n",
    "    labels, counts = np.unique(train_generator.labels, return_counts=True)\n",
    "    img_size = train_generator.target_size\n",
    "    batch_size = train_generator.batch_size\n",
    "    rotation = 45\n",
    "    datagen = ImageDataGenerator(rotation_range=rotation,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode=\"constant\",\n",
    "                                 validation_split=0.2\n",
    "                                 )\n",
    "    subset = 'validation' if suf_dir == 'test' else 'training'\n",
    "    for label in train_generator.class_indices.keys():\n",
    "        items_count = counts[np.where(\n",
    "            labels == train_generator.class_indices[label])[0][0]]\n",
    "        start_items = max_items\n",
    "        if items_count < max_items:\n",
    "            os.mkdir(os.path.join(working_dir, label))\n",
    "            datagen_new = datagen.flow_from_directory(train_generator.directory,\n",
    "                                                      subset=subset,\n",
    "                                                      target_size=(256, 256),\n",
    "                                                      batch_size=1,\n",
    "                                                      seed=SEED,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      save_to_dir=os.path.join(\n",
    "                                                          working_dir, label),\n",
    "                                                      classes=[label],\n",
    "                                                      save_prefix=f\"new_{label}\",\n",
    "                                                      save_format=\"jpeg\")\n",
    "\n",
    "            for _ in range(max_items - items_count):\n",
    "                next(datagen_new)\n",
    "            start_items = items_count\n",
    "            print(\n",
    "                f\"Добавлено {max_items - items_count} элеметов в класс {label}\\n\")\n",
    "        else:\n",
    "            print(f\"Выбрано {max_items} элеметов из класса {label}\\n\")\n",
    "        files = list(map(lambda x: x if label == x.split(\n",
    "            '\\\\')[0] else '', train_generator.filenames))\n",
    "        files = [x for x in files if x]\n",
    "\n",
    "        for i in range(start_items):\n",
    "            os.makedirs(os.path.dirname(os.path.join(\n",
    "                working_dir, label+'\\\\')), exist_ok=True)\n",
    "            shutil.copy(os.path.join(\n",
    "                train_generator.directory, files[i]), os.path.join(working_dir, label))\n",
    "\n",
    "    train_generator = ImageDataGenerator(rescale=1. / 255.).flow_from_directory(working_dir,\n",
    "                                                                                target_size=(\n",
    "                                                                                    256, 256),\n",
    "                                                                                batch_size=batch_size,\n",
    "                                                                                shuffle=False,\n",
    "                                                                                class_mode='categorical',\n",
    "                                                                                color_mode='rgb')\n",
    "\n",
    "    return train_generator, working_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процедура добавления изменённых экземпляров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_transformed(image_path, classes_dict, max_add_items):\n",
    "    rotation = 30\n",
    "    datagen = ImageDataGenerator(rotation_range=rotation,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode=\"nearest\"\n",
    "                                 )\n",
    "    for label in classes_dict.keys():\n",
    "        datagen_new = datagen.flow_from_directory(image_path,\n",
    "                                                  batch_size=1,\n",
    "                                                  seed=SEED,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  save_to_dir=image_path + label,\n",
    "                                                  classes=[label],\n",
    "                                                  save_prefix=f\"added_{label}\",\n",
    "                                                  save_format=\"jpeg\")\n",
    "\n",
    "        if max_add_items is None:\n",
    "            max_add_items = len(datagen_new)*round((360/rotation))\n",
    "        for _ in range(max_add_items):\n",
    "            next(datagen_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расширение датасета "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_data_transformed(IMAGE_PATH, classes_dict, 250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка и разделение данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (128, 128)\n",
    "batch_size = 128\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255.,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    validation_split=0.2)\n",
    "train_generator = datagen.flow_from_directory(IMAGE_PATH,\n",
    "                                              subset='training',\n",
    "                                              target_size=img_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              class_mode='categorical',\n",
    "                                              color_mode='rgb')\n",
    "test_generator = datagen.flow_from_directory(IMAGE_PATH,\n",
    "                                             subset='validation',\n",
    "                                             target_size=img_size,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             class_mode='categorical',\n",
    "                                             color_mode='rgb')\n",
    "classes_number = train_generator.num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Балансировка количества экземпляров в каждом классе обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, working_dir = balance_data_size(train_generator, 800, 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_classes = int(\n",
    "    round(train_generator.samples/train_generator.num_classes+50, -2))\n",
    "print(f\"Количество экземляров на каждый класс: {samples_per_classes*10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator2, working_dir = balance_data_size(\n",
    "    train_generator, samples_per_classes*10, 'train2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator, working_dir = balance_data_size(test_generator, 200, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование генераторов в плоские массивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_iterator.classes\n",
    "y_train = train_iterator.classes\n",
    "\n",
    "x_test = np.concatenate([test_iterator.next()[0] for _ in range(\n",
    "    test_iterator.__len__())]).reshape(y_test.shape[0], -1)\n",
    "x_train = np.concatenate([train_iterator.next()[0] for _ in range(\n",
    "    train_iterator.__len__())]).reshape(y_train.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на обучающую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data={'path': train_iterator2.filepaths, 'label': list(\n",
    "    map(lambda x: x.split('\\\\')[0], train_iterator2.filenames))})\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df, train_size=0.8, shuffle=True, random_state=SEED, stratify=train_df['label'])\n",
    "train_iterator_df = ImageDataGenerator(rescale=1. / 255.).flow_from_dataframe(train_df,\n",
    "                                                                              x_col='path',\n",
    "                                                                              y_col='label',\n",
    "                                                                              target_size=(\n",
    "                                                                                  256, 256),\n",
    "                                                                              class_mode='categorical',\n",
    "                                                                              batch_size=128,\n",
    "                                                                              shuffle=False,\n",
    "                                                                              color_mode='rgb')\n",
    "valididation_iterator_df = ImageDataGenerator(rescale=1. / 255.).flow_from_dataframe(valid_df,\n",
    "                                                                                     x_col='path',\n",
    "                                                                                     y_col='label',\n",
    "                                                                                     target_size=(\n",
    "                                                                                         256, 256),\n",
    "                                                                                     class_mode='categorical',\n",
    "                                                                                     batch_size=128,\n",
    "                                                                                     shuffle=False,\n",
    "                                                                                     color_mode='rgb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример изображения и его гистограммы после обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_image_with_hist(train_iterator[0][0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "x_reduced = pca.fit_transform(x_train)\n",
    "\n",
    "print('Projecting %d-dimensional data to 2D' % x_train.shape[1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_reduced[:, 0], x_reduced[:, 1], c=y_train,\n",
    "            edgecolor='none', alpha=0.7, s=40,\n",
    "            cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
    "plt.colorbar()\n",
    "plt.title('PCA projection')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA().fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), color='k', lw=2)\n",
    "plt.xlabel('Количество признаков')\n",
    "plt.ylabel('Итоговая дисперсия')\n",
    "plt.xlim(0, 800)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.axvline(300, c='b')\n",
    "plt.axhline(0.95, c='r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(0.95).fit(x_train)\n",
    "x_train_reduced = pca.transform(x_train)\n",
    "x_test_reduced = pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение данных для кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = RepeatedKFold(n_splits=5, n_repeats=1,  random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка матрицы неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heat(y_test, y_pred):\n",
    "    class_names = y_test\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plt.title('Матрица неточностей')\n",
    "    ticks = np.arange(len(class_names))\n",
    "    plt.xticks(ticks, class_names)\n",
    "    plt.yticks(ticks, class_names)\n",
    "    sns.heatmap(pd.DataFrame(\n",
    "        confusion_matrix(y_test, y_pred)),\n",
    "        annot=True)\n",
    "    plt.ylabel('Действительные значения')\n",
    "    plt.xlabel('Предсказанные значения')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(y_test, y_pred, classes_dict):\n",
    "    classes = list(classes_dict.keys())\n",
    "    length = len(classes)\n",
    "    if length < 8:\n",
    "        fig_width = 8\n",
    "        fig_height = 8\n",
    "    else:\n",
    "        fig_width = int(length * .5)\n",
    "        fig_height = int(length * .5)\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True,\n",
    "                vmin=0, fmt='g', cmap='RdPu', cbar=True)\n",
    "    plt.xticks(np.arange(length)+.5, classes, rotation=90)\n",
    "    plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
    "    plt.xlabel(\"Предсказанные значения\")\n",
    "    plt.ylabel(\"Действительные значения\")\n",
    "    plt.title(\"Матрица неточностей\")\n",
    "    plt.show()\n",
    "    class_rep = classification_report(y_test, y_pred, target_names=classes)\n",
    "    print(\"Classification Report:\\n----------------------\\n\", class_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка графика с ошибкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_err(x, data, **kwargs):\n",
    "    data_mean, data_std = data.mean(axis=1), data.std(axis=1)\n",
    "    lines = plt.plot(x, data_mean, '-', **kwargs)\n",
    "    plt.fill_between(x, data_mean - data_std, data_mean + data_std, edgecolor='none',\n",
    "                     facecolor=lines[0].get_color(), alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка обучающих кривых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_variance(stds, n=5):\n",
    "    return np.sqrt(sum((n-1)*(stds**2)) / len(stds)*(n-1))\n",
    "\n",
    "\n",
    "def print_learning_curve(grid_result, parameters):\n",
    "    df = pd.DataFrame(grid_result.cv_results_)\n",
    "    results = ['mean_test_score',\n",
    "               'mean_train_score',\n",
    "               'std_test_score',\n",
    "               'std_train_score']\n",
    "    fig, axes = plt.subplots(1, len(parameters), figsize=(\n",
    "        5*len(parameters), 7))\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    for i, (param_name, param_range) in enumerate(parameters.items()):\n",
    "        grouped_df = df.groupby(f'param_{param_name}')[results]\\\n",
    "            .agg({'mean_train_score': np.mean,\n",
    "                  'mean_test_score': np.mean,\n",
    "                  'std_train_score': pooled_variance,\n",
    "                  'std_test_score': pooled_variance})\n",
    "        axes[i].set_xlabel(param_name)\n",
    "        if isinstance(parameters[param_name][0], str):\n",
    "            x = np.arange(len(param_range))\n",
    "            width = 0.35\n",
    "            axes[i].bar(x-width/2,\n",
    "                        grouped_df['mean_train_score'],\n",
    "                        width,\n",
    "                        yerr=[grouped_df['mean_train_score'] - grouped_df['std_train_score'],\n",
    "                              grouped_df['mean_train_score'] + grouped_df['std_train_score']],\n",
    "                        color=\"red\",\n",
    "                        error_kw={'elinewidth': 1, 'capsize': 6},\n",
    "                        label=\"Training score\")\n",
    "            axes[i].bar(x + width/2,\n",
    "                        grouped_df['mean_test_score'],\n",
    "                        width,\n",
    "                        yerr=[grouped_df['mean_test_score'] - grouped_df['std_test_score'],\n",
    "                              grouped_df['mean_test_score'] + grouped_df['std_test_score']],\n",
    "                        color=\"green\",\n",
    "                        alpha=0.6,\n",
    "                        error_kw={'elinewidth': 1, 'capsize': 10},\n",
    "                        label=\"Cross-validation score\")\n",
    "            axes[i].set_xticks(x)\n",
    "            axes[i].set_xticklabels(param_range)\n",
    "        else:\n",
    "            #axes[i].set_ylim(0.0, 1.1)\n",
    "            axes[i].plot(param_range,\n",
    "                         grouped_df['mean_train_score'],\n",
    "                         label=\"Training score\",\n",
    "                         color=\"red\",\n",
    "                         lw=2)\n",
    "            axes[i].fill_between(param_range,\n",
    "                                 grouped_df['mean_train_score'] -\n",
    "                                 grouped_df['std_train_score'],\n",
    "                                 grouped_df['mean_train_score'] +\n",
    "                                 grouped_df['std_train_score'],\n",
    "                                 alpha=0.2,\n",
    "                                 color=\"red\",\n",
    "                                 lw=2)\n",
    "            axes[i].plot(param_range,\n",
    "                         grouped_df['mean_test_score'],\n",
    "                         label=\"Cross-validation score\",\n",
    "                         color=\"green\",\n",
    "                         lw=2)\n",
    "            axes[i].fill_between(param_range,\n",
    "                                 grouped_df['mean_test_score'] -\n",
    "                                 grouped_df['std_test_score'],\n",
    "                                 grouped_df['mean_test_score'] +\n",
    "                                 grouped_df['std_test_score'],\n",
    "                                 alpha=0.2,\n",
    "                                 color=\"green\",\n",
    "                                 lw=2)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.suptitle('Learning curves', fontsize=25)\n",
    "    fig.legend(handles, labels, loc=8, ncol=2, fontsize=15)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25, top=0.85)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция отчёта grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_report(grid_result):\n",
    "    print(\n",
    "        f\"Best: {grid_result.best_score_:.4f} using { grid_result.best_params_}\")\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"{mean:.4f} ({stdev:.4f}) with: {param}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение без учителя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "kmeans = KMeans(n_clusters=3, random_state=2).fit(x_train_reduced)\n",
    "kmeans_pred = kmeans.predict(x_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(y_test, kmeans_pred, classes_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "params_logreg = {'solver': ['lbfgs', 'sag',\n",
    "                            'saga'], 'C': np.logspace(-3, 3, 7)}\n",
    "logreg = LogisticRegression()\n",
    "grid_search_logreg = GridSearchCV(estimator=logreg,\n",
    "                                  param_grid=params_logreg,\n",
    "                                  scoring='f1_weighted',\n",
    "                                  cv=kfold,\n",
    "                                  return_train_score=True,\n",
    "                                  verbose=0)\n",
    "\n",
    "grid_result_logreg = grid_search_logreg.fit(x_train_reduced, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_report(grid_search_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = grid_result_logreg.predict(x_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(y_test, y_pred_logreg, classes_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающие кривые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_learning_curve(grid_result_logreg, params_logreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод опорных векторов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "params_svc = {'gamma': [0.01, 0.001], 'kernel': [\n",
    "    'rbf', 'poly', 'sigmoid'], 'C': [1, 10, 100, 1000]}\n",
    "svc = SVC()\n",
    "grid_search_svc = GridSearchCV(estimator=svc,\n",
    "                               param_grid=params_svc,\n",
    "                               scoring='f1_weighted',\n",
    "                               cv=kfold,\n",
    "                               return_train_score=True,\n",
    "                               verbose=0)\n",
    "\n",
    "grid_result_svc = grid_search_svc.fit(x_train_reduced, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_report(grid_result_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = grid_result_svc.predict(x_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(y_test, y_pred_svc, classes_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающие кривые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_learning_curve(grid_result_svc, params_svc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод k ближайших соседей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "params_kneighbors = {'n_neighbors': list(range(1, round(\n",
    "    x_train_reduced.shape[0]**(1/2)), 4)), 'weights': ['uniform', 'distance']}\n",
    "kneighbors = KNeighborsClassifier(n_neighbors=5)\n",
    "grid_search_kneighbors = GridSearchCV(estimator=kneighbors,\n",
    "                                      param_grid=params_kneighbors,\n",
    "                                      scoring='f1_weighted',\n",
    "                                      cv=kfold,\n",
    "                                      return_train_score=True,\n",
    "                                      verbose=0)\n",
    "\n",
    "grid_result_kneighbors = grid_search_kneighbors.fit(x_train_reduced, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_report(grid_result_kneighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kneighbors = grid_result_kneighbors.predict(x_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(y_test, y_pred_kneighbors, classes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_learning_curve(grid_result_kneighbors, params_kneighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Свёрточная нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(\n",
    "        2, (3, 3), input_shape=train_iterator2[0][0].shape[1:], padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(4, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(neurons, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, kernel_constraint=maxnorm(3),\n",
    "              activation='relu', kernel_regularizer='l2'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(classes_number))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, neurons=2, verbose=0)\n",
    "\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [5, 10, 20, 25]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad',\n",
    "             'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero',\n",
    "             'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation = ['softmax', 'softplus', 'softsign',\n",
    "              'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "neurons = [2, 4, 8, 16, 32, 64, 128]\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(model, param_grid=param_grid, cv=kfold)\n",
    "grid_result = grid.fit(x_train, y_train, epochs=40, batch_size=40)\n",
    "\n",
    "print(f\"Best: {grid_result.best_score_} using { grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"{mean} ({stdev}) with: {param}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "batch_size = 5\n",
    "model = Sequential()\n",
    "model.add(Conv2D(\n",
    "    2, (3, 3), input_shape=train_iterator2[0][0].shape[1:], padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(8, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, kernel_constraint=maxnorm(3),\n",
    "          activation='relu', kernel_regularizer='l2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(classes_number))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% % time\n",
    "history = model.fit(train_iterator_df, validation_data=valididation_iterator_df,\n",
    "                    epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report(test_iterator.classes, prediction.argmax(axis=1), classes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax[0].plot(epochs, accuracy, 'g', label='Training accuracy')\n",
    "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epochs, loss_values, 'g', label='Training loss')\n",
    "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Loss', fontsize=16)\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f358b5cc8431657c6d37c9f0231a5f5de1c9f4fd2b01e3553a8acc3d485fe0b2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
